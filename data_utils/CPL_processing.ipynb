{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742536/742536 [00:00<00:00, 1402004.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "f = open('nyt10_train_raw.json')\n",
    "dc = json.load(f)\n",
    "\n",
    "f = open('nyt10_test_raw.json')\n",
    "tmp = json.load(f)\n",
    "\n",
    "dc = dc + tmp\n",
    "\n",
    "data_corpus = []\n",
    "\n",
    "for item in tqdm(dc):\n",
    "    head, tail, relation = item['head']['id'], item['tail']['id'], item['relation']\n",
    "    triple = head + '\\t' + relation + '\\t' + tail\n",
    "    data_corpus.append(triple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268280\n"
     ]
    }
   ],
   "source": [
    "f = open('../../../../Volumes/Aux/Downloaded/Data-Upload/FB60K+NYT10/kg/train.txt')\n",
    "\n",
    "\n",
    "data_kg_train_raw = f.readlines()\n",
    "print(len(data_kg_train_raw))\n",
    "data_kg = []\n",
    "for line in data_kg_train_raw:\n",
    "    items = line[:-1].split('\\t')\n",
    "    head, relation, tail = items[0], items[1], items[2]\n",
    "    kg_triple = triple = head + '\\t' + relation + '\\t' + tail\n",
    "    data_kg.append(kg_triple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/business/company/founders',\n",
       " '/business/company/place_founded',\n",
       " '/business/person/company',\n",
       " '/location/administrative_division/country',\n",
       " '/location/country/administrative_divisions',\n",
       " '/location/location/contains',\n",
       " '/location/neighborhood/neighborhood_of',\n",
       " '/location/us_county/county_seat',\n",
       " '/people/deceased_person/place_of_death',\n",
       " '/people/ethnicity/people',\n",
       " '/people/person/children',\n",
       " '/people/person/ethnicity',\n",
       " '/people/person/nationality',\n",
       " '/people/person/place_lived',\n",
       " '/people/person/religion'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_relation_set = set()\n",
    "\n",
    "rel_list = ['/people/person/nationality', '/location/location/contains', '/people/person/place_lived', \n",
    "            '/people/deceased_person/place_of_death', '/people/person/ethnicity', '/people/ethnicity/people',\n",
    "            '/business/person/company', '/people/person/religion', '/location/neighborhood/neighborhood_of',\n",
    "            '/business/company/founders', '/people/person/children', '/location/administrative_division/country',\n",
    "            '/location/country/administrative_divisions', '/business/company/place_founded', '/location/us_county/county_seat']\n",
    "\n",
    "for i in range(len(rel_list)):\n",
    "    valid_relation_set.add(rel_list[i])\n",
    "    \n",
    "valid_relation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742536/742536 [00:00<00:00, 2488724.12it/s]\n",
      "100%|██████████| 268280/268280 [00:00<00:00, 2177800.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data_corpus_new = []\n",
    "data_kg_new = []\n",
    "# filter relation\n",
    "for item in tqdm(data_corpus):\n",
    "    if item.split('\\t')[1] in valid_relation_set:\n",
    "        data_corpus_new.append(item)\n",
    "\n",
    "for item in tqdm(data_kg):\n",
    "    if item.split('\\t')[1] in valid_relation_set:\n",
    "        data_kg_new.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143493, 59152)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_corpus_new), len(data_kg_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('../../../../CPL_processed_data/train_relfact2scope.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data_cpl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corpus_cpl = []\n",
    "\n",
    "for triple in data_cpl.keys():\n",
    "    head, tail, relation = triple.split('#')\n",
    "    if relation in valid_relation_set:\n",
    "        triple = head + '\\t' + relation + '\\t' + tail\n",
    "        data_corpus_cpl.append(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1751/1751 [00:00<00:00, 2067631.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open('../../../../CPL_processed_data/test_relfact2scope.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data_cpl_test = json.load(f)\n",
    "\n",
    "data_corpus_cpl_test = []\n",
    "\n",
    "for triple in data_cpl_test.keys():\n",
    "    head, tail, relation = triple.split('#')\n",
    "    if relation in valid_relation_set:\n",
    "        triple = head + '\\t' + relation + '\\t' + tail\n",
    "        data_corpus_cpl_test.append(triple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_corpus_cpl)\n",
    "\n",
    "nc_set = set(x for x in data_corpus_new)\n",
    "dcc_set = set(x for x in data_corpus_cpl)\n",
    "kg_set = set(x for x in data_kg_new)\n",
    "cpl_test_set = set(x for x in data_corpus_cpl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6919, 6919, 17639)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_nc_kg = nc_set.intersection(kg_set)\n",
    "inter_dcc_kg = dcc_set.intersection(kg_set)\n",
    "inter_nc_dcc = nc_set.intersection(dcc_set)\n",
    "len(inter_dcc_kg), len(inter_nc_kg), len(inter_nc_dcc), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = kg_set.union(dcc_set)\n",
    "\n",
    "data_train = \"\"\n",
    "for triple in tqdm(train_set):\n",
    "    data_train += triple + '\\n'\n",
    "\n",
    "train = open(\"../train.txt\", 'w', encoding='utf-8')\n",
    "print(data_train[:-1], file=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
